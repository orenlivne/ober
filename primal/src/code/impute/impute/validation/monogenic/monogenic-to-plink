#!/bin/bash
#----------------------------------------------------------------
# Compare Jessica's rare SNPs Dakota data to imputed genotypes.
# 
# Author: Oren E. Livne
# Date:   11-JUN-2013
#----------------------------------------------------------------

#--------------------------------------------------------------
# Constants
#--------------------------------------------------------------
FAM_FILE="$OBER/testdata/pedigree/hutterites.genotyped.tfam"
CGI_ID_FILE="${OBER_DATA}/cgi/README.assembly_sample_subject.csv"

#--------------------------------------------------------------
# Find genotype differences between Dakota, imputed genotypes.
#--------------------------------------------------------------
function genotype_diff
{
    plink="plink --noweb"
    in="$1"  # Input file prefix. Comparing in vs. in.imputed ped data sets.
    out="$2" # Output file prefix
    echo "Genotype differences, ${in} data set"

    # Find genotype differences
    $plink --file ${in} --merge ${in}.imputed.ped ${in}.imputed.map --out ${out} --merge-mode 6 --keep-allele-order >& /dev/null

    # Break down concordance by minor allele frequency. In progress...
    $plink --freq --file ${in} --out ${in} --nonfounders >& /dev/null

    # Count how many occurrences of xx/00 and 00/xx there are per each SNP. Append 0's if SNP not found
    # in the diff file.
    sed '1d' ${out}.diff | awk '{ if (($4 == "0/0") || ($5 == "0/0")) { print $1; } }' | sort | uniq -c | awk '{print $1, $2}' > missing.list
    comm -3 <(awk '{print $2}' ${in}.map | sort) <(awk '{print $2}' missing.list) | awk '{print 0, $1}' >> missing.list

    # Count how many discordances there are per each SNP. Append 0's if SNP not found in the diff file.
    sed '1d' ${out}.diff | awk '{ if (($4 != "0/0") && ($5 != "0/0")) { print $1; } }' | sort | uniq -c | awk '{print $1, $2}' > discordance.list
    comm -3 <(awk '{print $2}' ${in}.map | sort) <(awk '{print $2}' discordance.list) | awk '{print 0, $1}' >> discordance.list

    join --check-order -1 1 -2 2 <(join --check-order -1 1 -2 2 <(sed '1d' ${in}.frq | awk '{print $2, $5, $6}' | sort -k 1,1) <(sort -k 2,2 missing.list) | awk '{print $1, $2, $3, $4}') <(sort -k 2,2 discordance.list) | awk '{print $1, $2, $3, $4, $5}' > ${out}.concord

    # Report non-missing differences
    $plink --file ${in} --merge ${in}.imputed.ped ${in}.imputed.map --out ${out} --merge-mode 7 --keep-allele-order >& /dev/null
}

#--------------------------------------------------------------
# Main program
#--------------------------------------------------------------
in_dir="$1"
name="monogenic" # Data set name
work="${in_dir}/work"
save_dir="${OBER}/doc/imputation/${name}"

# Initialize
plink="plink --noweb"
#rm -rf ${work}
mkdir -p ${work}
cd ${in_dir}

# Extract CGI data to PLINK TPED
sed 1d ${in_dir}/snps.csv | sed 's/".*"/#/g' | awk -F, '{print $10}' > tmp
${OBER_CODE}/impute/batch/cgi/run_extract_imputed.py -s -o tped -l letter -f full $OBER_OUT/impute_cgi/imputed-override/imputed_cgi tmp ${work}/${name}.imputed.tped
rm tmp

# Convert Dakota files to standard file names
while read line; do
    snp_name=`echo ${line} | awk '{print $1}'`
    chr=`echo ${line} | awk '{print $2}'`
    bp=`echo ${line} | awk '{print $3}'`
    cp ${snp_name}.txt ${work}/chr${chr}_${bp}.txt >& /dev/null
done < <(join -j 1 --check-order <(cut -d' ' -f 1,4 ${work}/${name}.imputed.tped | awk '{printf "%02d%d %s %s\n", $1, $2, $1, $2;}' | sort -k 1,1) <(sed 1d snps.csv | sed 's/>/%3E/g' | sed 's/".*"/#/g' | sed 's/chr.*:.*-//g' | awk -F, '{printf "%02d%d %s %d %d\n", $2, $10, $8, $2, $10}' | sort -k 1,1) | awk '{print $4, $5, $6}')

# Convert special SNPs that were typed on multiple platforms to a single file with a standard name
cat CFTR_DF508* | grep -v 'subject' | awk '($2 != 0) || ($3 != 0)' | sed 's/103\t100/100\t103/g' | sort | uniq > ${work}/chr7_117199645.txt
cat CFTR_M1101K* | grep -v 'subject' | awk '($2 != 0) || ($3 != 0)' | sed 's/A\tT/T\tA/g' | sort | uniq > ${work}/chr7_117251797.txt

# Create PLINK PED set for Jessica's data
cd ${work}
sed '1d' ${in_dir}/snps-found.csv | awk -F, '{printf "%d\tchr%d_%d\t0\t%d\n", $1, $1, $5, $5}' > ${name}.map
rm -f ${name}.lgen
for snp_name in `awk '{print $2}' ${name}.map`; do
    chr=`echo ${snp_name} | sed 's/chr\(.*\)_\(.*\)/\1/g'`
    bp=`echo ${snp_name} | sed 's/chr\(.*\)_\(.*\)/\2/g'`
    sed '1d' chr${chr}_${bp}.txt | egrep -v "CONTROL" | awk -v snp_name="${snp_name}" '{ printf "%s\t%s\t%s\t%s\t%s\n", "HUTTERITES", $1, snp_name, $2, $3; }' >> ${name}.lgen
done

$plink --nonfounders --lgen ${name}.lgen --map ${name}.map --fam ${FAM_FILE} --out ${name} --recode >& /dev/null

# Convert CGI to PLINK PED
$plink --nonfounders --tped ${name}.imputed.tped --tfam ${FAM_FILE} --out ${name}.imputed --recode >& /dev/null
$plink --file ${name} --merge ${name}.imputed.ped ${name}.map --out ${name} --merge-mode 6 --keep-allele-order >& /dev/null
# Standardize snp names
cp ${name}.map ${name}.imputed.map
# Standardize allele coding to CGI values
if [ -f ${name}.missnp ]; then
    for s in ${name} ${name}.imputed; do
	$plink --file $s --out $s --make-bed --keep-allele-order --nonfounders >& /dev/null
    done
    paste ${name}.bim ${name}.imputed.bim | awk '{print $2, $5, $6, $11, $12}' > ${name}.recode
    $plink --file ${name} --out ${name} --recode --update-alleles ${name}.recode --nonfounders >& /dev/null
fi

# Find genotype differences, all samples
genotype_diff ${name} ${name}

# Find sample intersection of the Dakota and CGI WGS sets
for s in ${name} ${name}.imputed; do
    $plink --file $s --out $s --recode --transpose >& /dev/null
done
join --check-order -1 2 -2 1 <(sort -k 2,2 ${name}.tfam) <(sed '1d' ${CGI_ID_FILE} | awk -F, '{print $3}' | sort) | awk '{print $2, $1}' > common-samples.tfam

# Find genotype differences in CGI samples
$plink --file ${name} --out ${name}.common --keep common-samples.tfam --recode >& /dev/null
$plink --file ${name}.imputed --out ${name}.common.imputed --keep common-samples.tfam --recode >& /dev/null

# Tag differences as WGS or not WGS
( printf "%s\t\t%s\t%s\t%s\t%s\n" "SNP" "Sample" "Imputed" "Dakota" "WGS?" ; ( join -1 3 -2 1 <(sed '1d' ${name}.diff | sort -k 3,3) <(comm -12 <(sed '1d' ${name}.diff| awk '{print $3'} | uniq | sort) <(awk '{print $2}' common-samples.tfam | sort)) | awk '{printf "%s\t%s\t%s\t%s\t%s\n", $2, $1, $4, $5, "WGS"}' ; join -1 3 -2 1 <(sed '1d' ${name}.diff | sort -k 3,3) <(comm -23 <(sed '1d' ${name}.diff| awk '{print $3'} | uniq | sort) <(awk '{print $2}' common-samples.tfam | sort)) | awk '{printf "%s\t%s\t%s\t%s\t%s\n", $2, $1, $4, $5, "-"}') | sort -k 1,1 ) > ${name}.difftag

# Convert to 12 TPED so that we can run validation on it
plink --noweb --nonfounders --tfile ${name} --recode12 --transpose --out ${name}.12

# Find genotype differences, CGI samples only
plink --noweb --file ${name} --out ${name}.common --keep common-samples.tfam --recode >& /dev/null
plink --noweb --file ${name}.imputed --out ${name}.common.imputed --keep common-samples.tfam --recode >& /dev/null
genotype_diff ${name}.common ${name}.common

#----------------------------
# Run validation programs
#----------------------------
# Generate plots - genotype vs. imputed concordance
python ${OBER_CODE}/impute/impute/validation/plot_impute_concordance.py ${name}.concord ${name}.common.concord "Rare Variants" ${save_dir} > ${save_dir}/${name}.discord
cp ${name}.concord ${name}.common.concord ${save_dir}

# Manually re-impute, validate concordance
# TBA python monogenic_validation.py ...

# Clean temporary files
echo "Clean up"
cd ${work}
rm -rf *.txt *.bed *.ped *.nof *.log *.list *.map *.recode *.missnp *.frq *.bim *.fam *.lgen
#rm -rf ${work}
