#!/bin/bash
#------------------------------------------------------------------------
# Prepare data an IMPUTE2 parallel run.
#
# Match strands and allele coding between the Affy and CGI data sets.
# Create a list of non-matching and discordant SNPs to be excluded from
# the input data set to IMPUTE2 (and in the future possibly also from
# our imputation).
# 
# Author: Oren E. Livne
# Date:   13-SEP-2013
#------------------------------------------------------------------------

#=======================================
# Constants
#=======================================
# Affymetrix phasing result directory
affy_home="${OBER_OUT}/phasing"
# Affymetrix PLINK SNP metadata file
affy_bim="${OBER_OUT}/phasing/hutt.bim"
# WGS CGI genotype file prefix
cgi_genotypes_home="${OBER_OUT}/impute_cgi/genotypes/genotypes"
# Imputed CGI genotype file prefix (genotypes are phased)
imputed_genotypes_home="${OBER_OUT}/impute_cgi/imputed-override/imputed_cgi"
# 0-based indices of WGS samples in imputed data files
wgs_index="${OBER_OUT}/impute_cgi/imputed-override/hutterites.wgs.index"
# 0-based indices of non-WGS samples in imputed data files
imputed_index="${OBER_OUT}/impute_cgi/imputed-override/hutterites.imputed.index"
#imputed_index="${OBER_OUT}/impute_cgi/impute2/hutterites.test.index"
# Prefix of HapMap recombination map files
maps="${OBER_DATA}/common/map/genetic_map_GRCh37"
# Prefix of chunk output files
out_prefix="run_impute2"

#=======================================
# Read input parameters
#=======================================
DARGS=65
PROGNAME=`basename $0`

function read_input_args
{
    #%%%%%%%%%%%%%%%%%%%%%%%%
    # Default argument values
    #%%%%%%%%%%%%%%%%%%%%%%%%
    # Number of nodes to chunk data into
    nodes="1"
    # Number of instances per node
    instances_per_node="24"
    # Length of buffer region (in kb) to include on each side of the analysis interval
    # specified by the IMPUTE2 -int option
    buffer="250000"
    # Minimum call rate of variants to be imputed
    min_call_rate="0.95"
    # Only these types variants are imputed (the rest are not trusted based on our CGI QC pipeline)
    trusted_variant_types='snp|del|sub'
    # Maximum allowed CGI-Affy discordance rate for variants to be included in study panel
    max_discordance_rate="0.05"
    # Output directory
    out_dir="${OBER_OUT}/impute_cgi/impute2"
    # Input phased or unphased data into IMPUTE2?
    phased=false
    # Turn on options for validation vs. pedigree-based imputation. Increases run time.
    validation=false
    # Number of parallel processes to spawn during run
    processes="1"

    # Read input arguments
    while getopts "hn:i:b:o:pvj:" optionName; do
	case "$optionName" in
	    n) nodes="$OPTARG";;
	    i) instances_per_node="$OPTARG";;
	    b) buffer="$OPTARG";;
	    o) out_dir="$OPTARG";;
	    p) phased=true;;
	    v) validation=true;;
	    j) processes="$OPTARG";;
	    h) print_usage; exit 0;;
	    [?]) print_type_for_help;;
       esac
    done

    # Get mandatory arguments
    shift $(( $OPTIND -1 ))
    if [[ $# -ne 1 ]]; then
  	echo "Chromosome # should be specified."
	print_type_for_help
    fi
    chrom="$1"

    # Convenient aliases
    affy_genotypes="${affy_home}/chr${chrom}/hutt.tped"
    cgi_genotypes="${cgi_genotypes_home}.chr${chrom}.tsv.gz"
    imputed_genotypes="${imputed_genotypes_home}.chr${chrom}.tsv.gz"
    # Reference haplotypes (WGS 98 at CGI SNPs)
    if ${phased}; then
	suffix="haps"
	ref_name="haplotypes"
	phased_flags="-p"
	gen_format="imputed"
    else
	suffix="gen"
	ref_name="genotypes"
	phased_flags=""
	gen_format="cgi"
    fi
    ref_panel="${out_dir}/ref.${suffix}"
    # Allele frequencies of reference panel
    ref_frq="${out_dir}/ref.frq.${suffix}"
    # Our imputed haplotypes (non-WGS 1317 at CGI SNPs) for validation of impute2 results
    imputed_haps="${out_dir}/imputed.${suffix}"
    study_panel="${out_dir}/study.${suffix}"
    # Filtered common Affy-CGI SNP file
    snps_ok="${out_dir}/snps-ok.out"
    # Reusable temporary file names
    variant_filtered="${out_dir}/variants.filtered"
    all_imputed_genotypes="${out_dir}/all.imputed.${suffix}"
}

function print_usage
{
    echo -e "Usage: ${PROGNAME} <chrom> [flags]"
    echo -e ""
    echo -e "Prepare input for a parallel IMPUTE2 run."
    echo -e ""
    echo -e "Optional flags:"
    echo -e "\t-n nodes\t\tNumber of nodes to chunk data into. Default: ${nodes}"
    echo -e "\t-i instances-per-node\tNumber of instances per node. Default: ${instances_per_node}"
    echo -e "\t-b buffer\t\tLength of buffer region (in kb) to include on each side of"
    echo -e "\t\t\t\tthe analysis. Default: ${buffer}"
    echo -e "\t-o out-dir\t\tOutput directory. Default: ${out_dir}"
    echo -e "\t\t\t\tinterval specified by the IMPUTE2 -int option. Default: ${buffer}"
    echo -e "\t-j processes\t\tNumber of parallel processes to spawn during run.\n"
    echo -e "\t\t\t\tRequires parallel to be installed. Default: ${processes}"
    echo -e "\t-p\t\t\tInput phased data into IMPUTE2 (default: unphased data)?"
    echo -e "\t-v\t\t\tTurn on options for validation vs. pedigree-based imputation. Increases run time."
}

# Print help message and die
function print_type_for_help
{
    echo "Type \"${PROGNAME} -h\" for help."
    exit ${E_BADARGS}
}

#=======================================
# Business Logic
#=======================================
function cat_file 
{
    file="$1"
    if [[ -n `echo "${file}" | sed -n '/\(.*\)\.gz/p'` ]]; then
	CAT="zcat"
    else
	CAT="cat"
    fi
    ${CAT} ${file}
}

# Calculate overall call rate for a CGI compressed/uncompressed file.
function call_rate
{
    file="$1"
    metadata_cols="$2"
    delimiter="$3"
    missing="$4"
    if [[ ${delimiter} == '\t' ]]; then
	called=$( cat_file ${file} | cut -f $(( metadata_cols + 1 ))- | tr "${delimiter}" '\n' | egrep -v "${missing}" | wc -l )
    else
	called=$( cat_file ${file} | cut -f $(( metadata_cols + 1 ))- -d"${delimiter}" | tr "${delimiter}" '\n' | egrep -v "${missing}" | wc -l )
    fi
    snps=$( cat_file ${file} | wc -l )
    samples=$( cat_file ${file} | head -1 | awk "{ print NF-${metadata_cols} }" )
    call_rate=`echo "scale=2; 100.0*${called}/(${snps}*${samples})" | bc`
    printf "SNPs %6d, call rate %4.2f%%\n" ${snps} ${call_rate}
}

# Find the intersection of CGI and Affy SNPs. Filter SNPs:
# (a) Check for discordances among homozygotes and flip affy coding if large.
# (b) If the affy genotype is called, check if the CGI genotype is called; if it is; check if discordant.
function run_qc
{
    out="${out_dir}/snps-cgi-affy.out"

    echo "Running SNP QC ..."
    join --check-order -1 4 -2 4 \
	<(zcat ${cgi_genotypes} | sed '1d' | awk '$5 == "snp" && match($8, /.*rs./)' | sort -k 4,4) \
	<(paste <(cat ${affy_genotypes} | imputed-genotypes -i ${wgs_index} tped) \
  	<(cat ${affy_bim} | awk -v chrom=${chrom} '$1 == chrom') | sort -k 4,4) \
	| sort -k 1,1n | awk \
    'BEGIN { r["A"]="A"; r["G"]="G"; r["C"]="G"; r["T"]="A"; } \
        { \
          N = (NF-17)/2; \
          concordant_hom = 0; \
          discordant_hom = 0; \
          for (i = 0; i < N; i++) \
          { \
            a = $(9+i); \
            b = $(110+i); \
            a1 = substr(a,1,1); \
            a2 = substr(a,2,1); \
            b1 = substr(b,1,1); \
            b2 = substr(b,2,1); \
            if ((a1 != "N") && (a1 == a2) && (b1 != "N") && (b1 == b2)) \
              if (a1 != b1) discordant_hom++; \
              if (a1 == b1) concordant_hom++; \
          } \
          reverse = (discordant_hom >= 3); \
          \
          discordant = 0; \
          called = 0; \
          for (i = 0; i < N; i++) \
          { \
            a = $(9+i); \
            b = $(110+i); \
            a1 = substr(a,1,1); \
            a2 = substr(a,2,1); \
            b1 = substr(b,1,1); \
            b2 = substr(b,2,1); \
            if ((a1 != "N") && (a2 != "N") && (b1 != "N") && (b2 != "N")) \
            { \
              if (reverse) { b1=1-b1; b2=1-b2; } \
              discordant += (a1+a2 != b1+b2); \
              called++; \
            } \
          } \
          can_flip_strand = (r[$6] != r[$(2*N+16)]) == (r[$7] != r[$(2*N+17)])
          printf "%s %s %s %s %s %s %s %s %s %d %d %d %.3f %.3f\n", \
          $2, $(N+9), $1, $(N+10), $(N+11), $6, $7, $(2*N+16), $(2*N+17), \
          can_flip_strand, reverse, discordant, (1.0*discordant)/(called+1e-15), (1.0*called)/N; \
        }' > ${out}

    # Number of reference samples
    ref_samples=`zcat ${cgi_genotypes} | sed '1d' | head -1 | awk '{print NF-8'}`
    # Number of study SNPs
    ref_snps=`wc -l ${affy_genotypes} | awk '{print $1}'`
    tot_discordant=`awk '{print $12}' ${out} | paste -sd+ | bc`
    error_rate=`printf "scale=3; (100.0*%d)/(%d*%d)\n" ${tot_discordant} ${ref_samples} ${ref_snps} | bc`
    # Run concordance and strand checks and remove bad SNPs. Don't filter on call rates here: we
    # could definitely use an affy SNP whose CGI call rate is not high - it's more information for IMPUTE2.
    awk -v e=${max_discordance_rate} -v t=${min_call_rate} '($13 <= e) && ($10 == 1)' ${out} > ${snps_ok}
    snps_bad="${out_dir}/snps-bad.out"
    awk -v e=${max_discordance_rate} -v t=${min_call_rate} '($13 >  e) || ($10 == 0)' ${out} > ${snps_bad}
    affy_snps=`wc -l ${affy_genotypes} | awk '{print $1}'`
    ok_snps=`wc -l ${snps_ok} | awk '{print $1}'`
    bad_snps=`wc -l ${snps_bad} | awk '{print $1}'`
    printf "Discordance rate %4.2f%% Affy SNPs %5d OK SNPs %5d Bad SNPs %3d\n" ${error_rate} ${affy_snps} ${ok_snps} ${bad_snps}
    echo "See bad SNP report ${out_dir}/report-discordant.out"
    awk 'BEGIN { printf "%-8s %-2s %-10s %-15s %-11s %-s%-s %-s%-s %-3s %-3s %-3s %-5s %-5s\n", "vid", "chr", "bp", "variant name", "cM", "CGI1", "CGI2", "Affy1", "Afy2", "Flippable", "#DisHom", "Dis", "DisRate", "CallRate"; } { printf "%8d %-2d %10d %-15s %11.6f %s%s %s%s %3d %3d %3d %5.3f %5.3f\n", $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14}' ${snps_bad} > ${out_dir}/report-snps-bad.out

    # Clean up
    rm -rf ${out} ${snps_bad}
}

# Prepare reference haplotype file (98 WGS at CGI SNPs, phased by our imputation program).
# This contains the list of (CGI WGS) variants to be imputed. Only impute variants with high
# call rate whose calls can be trusted (based on our generalized Mendelian check QC, these are
# SNPs, deletions, and substitutions).
function prepare_ref
{
    echo "Filtering WGS variants ..."
    if [ ! -f ${variant_filtered} ]; then
	all_cgi_genotypes="${out_dir}/all.cgi.genotypes"
	zcat ${cgi_genotypes} | sed '1d' > ${all_cgi_genotypes}
	count-genotypes -v -n 0 -g genotype ${all_cgi_genotypes} | \
	    awk -v v=${trusted_variant_types} -v t=${min_call_rate} \
	    '{ if (($13 >= t) && match($2, v)) { print $1; } }' | sort > ${variant_filtered}
	#rm -f ${all_cgi_genotypes}

	# Union with affy SNPs so that the reference panel contains the study panel
	lookup="${out_dir}/lookup"
	lookup_filtered="${out_dir}/lookup_filtered"
	cut -f 1,4 ${all_cgi_genotypes} | sort -k 1,1 > ${lookup}
	join -j 1 --check-order ${variant_filtered} ${lookup} > ${lookup_filtered}
        # Find all affy SNPs that are not in the filtered CGI variant list
	cat ${variant_filtered} \
	    <(join -1 1 -2 2 --check-order \
	    <(comm -13 <(cut -d' ' -f 2 ${lookup_filtered} | sort) <(cut -d' ' -f 3 ${snps_ok} | sort)) \
	    <(sort -k 2,2 ${lookup}) | cut -d' ' -f 2) | sort > tmp && mv tmp ${variant_filtered}
    fi
    printf "Restricting CGI data to %d filtered variants ...\n" `wc -l ${variant_filtered} | awk '{print $1}'`
    if [ ! -f ${all_imputed_genotypes} ]; then
	# Sort on column 3 (start_bp) that is later used to find start, end bp of chunks
	join -j 1 --check-order ${variant_filtered} <(cat_file ${imputed_genotypes} | sort -k 1,1) | sort -k 3,3n > ${all_imputed_genotypes}
    fi

    echo "Preparing reference ${ref_name} ..."
    echo "# WGS samples: `wc -l ${wgs_index} | awk '{print $1}'`"
    cat ${all_imputed_genotypes} | imputed-genotypes -d' ' -i ${wgs_index} ${phased_flags} ${gen_format} > ${ref_panel}
    if $validation; then
	echo "Preparing imputed haps at reference panel SNPs (for validation only) ..."
	echo "# samples to impute: `wc -l ${imputed_index} | awk '{print $1}'`"
	cat ${all_imputed_genotypes} | imputed-genotypes -d' ' -i ${imputed_index} -p cgi > ${imputed_haps}
    fi

    # Clean up
    rm -f ${lookup} ${lookup_filter}
    #rm -f ${all_cgi_genotypes} # ${all_imputed_genotypes}
}

# Calculate WGS 98 call rate of reference haplotype file. Should be at least the CGI genotype
# call rate. For debugging.
function check_call_rate
{
    if [ ! -f ${out_dir}/cgi.call.${suffix} ]; then
	join -j 1 --check-order ${variant_filtered} <(zcat ${cgi_genotypes} | sed '1d' | sort -k 1,1) > \
	    ${out_dir}/cgi.call.${suffix}
    fi
    a=$( call_rate ${out_dir}/cgi.call.${suffix} 8 ' ' 'N' )
    echo "WGS CGI genotypes: ${a}"

    if [[ $validation == true && ( ! -f ${out_dir}/ref.call.${suffix} ) ]]; then
	cat ${all_imputed_genotypes} | imputed-genotypes -d' ' -i ${wgs_index} ${phased_flags} cgi > \
	    ${out_dir}/ref.call.${suffix}
	b=$( call_rate ${out_dir}/ref.call.${suffix} 5 ' ' '\?')
	echo "Reference panel  : ${b}"
    fi
    echo ""
}

# Prepare study haplotype file (1317 non-WGS at affy SNPs, phased by our phasing program),
# flipping strand to match the CGI reference haplotypes.
function prepare_study_haps
{
    python -c "import impute as im, numpy as np; h = im.io.read_npz('${affy_home}/chr${chrom}/hutt.phased.npz').haplotype; s=np.loadtxt('${out_dir}/snps-ok.flip', dtype=int); im.io_genotype.write('impute2', h, open('${study_panel}', 'wb'), samples=np.array([`paste -sd, ${imputed_index}`]), snps=s[:,0], flip_alleles=s[:,1].astype(bool))"
}

# Prepare study genotype file (1317 non-WGS at affy SNPs, phased by our phasing program),
# flipping strand to match the CGI reference haplotypes.
function prepare_study_gen
{
    # Relevant columns to extract from the join command
    cols="1-5"`paste -sd' ' ${imputed_index} | awk '{ for (i = 1; i <= NF; i++) { printf ",%d-%d", 3*$i+6, 3*$i+8; } }'`
    # Convert the affy 12-recoded PLINK TPED file to IMPUTE2 genotype dosage format. Join with SNP metadata.
    paste \
	<(join --check-order -1 3 -2 4 <(sort -k 3,3 ${snps_ok}) <(sort -k 4,4 ${affy_genotypes}) | sort -k 3,3) \
	${out_dir}/snps-ok.flip \
	>${out_dir}/tmp

    paste \
	<(join --check-order -1 3 -2 4 <(sort -k 3,3 ${snps_ok}) <(sort -k 4,4 ${affy_genotypes}) | sort -k 3,3) \
	${out_dir}/snps-ok.flip | awk '{ \
          printf "%s %s %s %s %s", $2, $4, $1, $6, $7; \
          reverse = $(NF); \
          for (i = 18; i <= NF-2; i += 2)
          { \
            dose = $i + $(i+1);
            if      (dose == 0) printf " ? ? ?"; \
            else if (dose == (reverse ? 4 : 2)) printf " 1 0 0"; \
            else if (dose ==                 3) printf " 0 1 0"; \
            else if (dose == (reverse ? 2 : 4)) printf " 0 0 1"; \
            else { print "Impossible dosage encountered" > "/dev/stderr"; exit 1; } \
          } \
          printf "\n";
        }' | cut -d' ' -f ${cols} > ${study_panel}
}

# Split a single chunk from the master input data set.
function create_chunk
{
    local out_dir="$1"
    local chrom="$2"
    local instances_per_node="$3"
    local suffix="$4"
    local part_id="$5"

    # Redefine variables global to this function (or pass all of them in)
    maps="${OBER_DATA}/common/map/genetic_map_GRCh37"
    out_prefix="run_impute2"
    ref_panel="${out_dir}/ref.${suffix}"
    ref_frq="${out_dir}/ref.frq.${suffix}"
    imputed_haps="${out_dir}/imputed.${suffix}"
    study_panel="${out_dir}/study.${suffix}"
    snps_ok="${out_dir}/snps-ok.out"
    
    file=`printf "%s/node-%04d/%s-%04d.in" ${out_dir} $(( part_id / instances_per_node )) ${out_prefix} ${part_id}`

    # [start_bp,stop_bp] = reference region to be imputed
    # [start_study,stop_study] = study panel region (contains the reference region)
    # [start_map,stop_map] = genetic recombination map region (contains the reference region)

    # Make sure that CGI region is within the affy region (IMPUTE2 restriction).
    # In particular, IMPUTE2 won't impute before the first affy SNP and after the last affy SNP.
    start_bp=`head -1 ${file} | awk '{print $3}'`
    stop_bp=`tail -1 ${file} | awk '{print $3}'`
    start_study=`head -1 ${snps_ok} | awk '{print $3}'`
    stop_study=`tail -1 ${snps_ok} | awk '{print $3}'`
    if [[ ${start_bp} -lt ${start_study} ]]; then start_bp=${start_study}; fi
    if [[ ${stop_bp}  -gt ${stop_study}  ]]; then stop_bp=${stop_study};   fi

    size_in_mb=`printf "scale=2; (%d-%d)/(1000000.)\n" ${stop_bp} ${start_bp} | bc`

    # Prepare genetic map file; pad base pair region
    (( start_map = start_bp - buffer ))
    (( stop_map  = stop_bp  + buffer ))
    ( echo "position COMBINED_rate(cM/Mb) Genetic_Map(cM)" ; \
	sed '1d' ${maps}_chr${chrom}.txt | awk -v start=${start_map} -v stop=${stop_map} \
	'{ if (($2 >= start) && ($2 <= stop)) { print $2, $3, $4; } }' ) > ${file%.*}.map

    # Prepare SNP legend file (like PLINK MAP SNP metadata)
    ( echo "rsID position a0 a1" ; awk -v start=${start_bp} -v stop=${stop_bp} \
	'($3 >= start) && ($3 <= stop)' ${ref_panel} | awk '{ print $1, $3, $4, $5 }' ) > ${file%.*}.legend

    # Create reference haplotypes
    if ${phased}; then
	# For IMPUTE2 reference haplotype format: omit SNP meta data columns
	awk -v start=${start_bp} -v stop=${stop_bp} \
	'($3 >= start) && ($3 <= stop)' ${ref_panel} | cut -d' ' -f 6- > ${file%.*}.ref.${suffix}
    else
	# For IMPUTE2 reference genotype format: keep SNP meta data columns
	awk -v start=${start_bp} -v stop=${stop_bp} \
	'($3 >= start) && ($3 <= stop)' ${ref_panel} > ${file%.*}.ref.${suffix}
    fi
    awk -v start=${start_bp} -v stop=${stop_bp} \
	'($3 >= start) && ($3 <= stop)' ${ref_frq} > ${file%.*}.frq.${suffix}

    # Counterpart of reference file for validation - imputed results from us on non-WGS samples in this chunk
    awk -v start=${start_bp} -v stop=${stop_bp} \
	'($3 >= start) && ($3 <= stop)' ${imputed_haps} | cut -d' ' -f 6- > ${file%.*}.imputed.${suffix}

    # Create study haplotypes
    # Pad to get all study SNPs within the reference bp range, plus one more one either side
    # to ensure that study region is equal to or contains reference region.
    # (Otherwise, IMPUTE2 will not impute the edges of the reference region.)
    start_study=`awk -v position=${start_bp} 'BEGIN { prev = -1; found = 0; } \
	{ if ($3 > position) { if (prev < 0) print $3; else print prev; found = 1; exit; } prev = $3; } \
	END { if (!found) print prev; }' ${snps_ok}`
    stop_study=`awk -v position=${stop_bp} 'BEGIN { nxt = -1; found = 0; } \
	{ if ($3 > position) { print $3; found = 1; exit; } nxt = $3; } \
	END { if (!found) print nxt; }' ${snps_ok}`

    end_col=`head -1 ${study_panel} | awk '{ print NF }'`

    affy_set="${file%.*}.ref.tmp"
    awk -v start=${start_study} -v stop=${stop_study} '($3 >= start) && ($3 <= stop)' ${snps_ok} | sort -k 3,3 > ${affy_set}
    if ${phased}; then
	# Haplotype format: join on base pair column (4th in study panel)
	join --check-order -1 4 -2 3 ${study_panel}.sorted ${affy_set} | \
	    awk -v e=${end_col} '{ printf "%s %s %s %s %s", $(e+1), $3, $1, $(e+5), $(e+6); \
            for (i = 5; i <= e; i++) { printf " %s", $i }; printf "\n"; }' | sort -k 3,3n > ${file%.*}.study.${suffix}
    else
	# Genotype format: join on base pair column (3rd in study panel). A bit easier to extract
        # relevant columns - except for swapping the first three, they are identical to master study file
	join --check-order -1 3 -2 3 ${study_panel} ${affy_set} | \
	    awk -v e=${end_col} '{ printf "%s %s %s", $2, $3, $1; \
            for (i = 4; i <= e; i++) { printf " %s", $i }; printf "\n"; }' > ${file%.*}.study.${suffix}
    fi

    printf "Chunk %4d: ref [%d,%d] study [%d,%d] %5.2f Mb (%s)\n" ${part_id} ${start_bp} ${stop_bp} ${start_study} ${stop_study} ${size_in_mb} ${file}
    rm -f ${affy_set}
}

#=======================================
# Main Program
#=======================================
# Parse CLI arguments
read_input_args "$@"

# Find the common SNPs between CGI SNP variants with RS numbers and the affy SNPs.
# Mark SNPs that have a flipped allele letters
# (after flipping strands to be the same)
echo "======================"
echo "Chromosome ${chrom}"
echo "======================"

mkdir -p ${out_dir}

do_rest=false
if [[ ( $do_rest == true ) || ( ! -f ${snps_ok} ) ]]; then
    do_rest=true
    run_qc
fi

if [[ ( $do_rest == true ) || ( ! -f ${ref_panel} ) ]]; then
    do_rest=true
    prepare_ref
fi

#check_call_rate

# Calculate MAF, total called haplotypes, minor allele number (0 of 1)  
if [[ ( $do_rest == true ) || ( ! -f ${ref_frq} ) ]]; then
    if $phased; then
	# Count haplotypes
	awk '{ \
          a["0"]=0; a["1"]=0; a["?"]=0; \
          for (i = 6; i <= NF; i++) a[$i]++; \
          a0 = a["0"]; \
          a1 = a["1"]; \
          b  = a0+a1; \
          for (i = 1; i <= 5; i++) printf "%s ", $i; \
          printf "%f %d %d\n", ((a0 < a1) ? a0 : a1)/(1.0*b+1e-15), b, ((a0 < a1) ? 0 : 1); \
        }' ${ref_panel} > ${ref_frq}
    else
	# Count genotypes (doses of the "1"-allele)
	awk '{ \
          a["0"]=0; a["1"]=0; a["2"]=0; a["?"]=0; \
          for (i = 6; i <= NF; i+=3) \
          { \
            if      ($i     == "?") { a["?"]++;           } \
            else if ($i     == "1") { a["0"] += 2;        } \
            else if ($(i+1) == "1") { a["0"]++; a["1"]++; } \
            else if ($(i+2) == "1") { a["1"] += 2;        } \
          } \
          a0 = a["0"]; \
          a1 = a["1"]; \
          b  = a0+a1; \
          for (i = 1; i <= 5; i++) printf "%s ", $i; \
          printf "%f %d %d\n", ((a0 < a1) ? a0 : a1)/(1.0*b+1e-15), b, ((a0 < a1) ? 0 : 1); \
    }' ${ref_panel} > ${ref_frq}
    fi
fi

if [[ ( $do_rest == true ) || ( ! -f ${study_panel} ) ]]; then
    echo "Prepare strand flipping file ..."
    join --check-order -1 2 -2 1 <(awk -v chrom=${chrom} 'BEGIN { i=0 } { if ($1 == chrom) { print i, $4 ; i++; } }'  ${affy_bim} | sort -k 2,2) <(awk '{print $3, $11}' ${snps_ok} | sort -k 1,1) | sort -k 1,1n | awk '{print $2, $3'} > ${out_dir}/snps-ok.flip

    echo "Preparing study ${ref_name} ..."
    if ${phased}; then
	prepare_study_haps
    else
	prepare_study_gen
    fi
fi

if [ ! -f ${study_panel}.sorted ]; then
    sort -k 4,4 ${study_panel} > ${study_panel}.sorted
fi

printf "Partitioning data into %d x %d non-overlapping chunks ...\n" ${nodes} ${instances_per_node}
# Break SNPs into approximately equal chunks. Dummy, so that pack_jobs.py can seamlessly work
if [ ! -f ${out_dir}/node-0000/${out_prefix}-0000.in ]; then
    split-nobreak -a 4 -b 4 ${ref_panel} "${out_dir}/node-" "" "${out_prefix}-" ".in" ${nodes} ${instances_per_node}
    
    # Note: Parallel run study panel join command broken so run only serial in that case.
    if [[ ( ${phased} == "false" ) || ( ${processes} -eq 1 ) ]]; then
    # Serial run
    for part_id in `seq 0 $(( nodes * instances_per_node - 1 ))`; do
	create_chunk ${out_dir} ${chrom} ${instances_per_node} ${suffix} ${part_id}
    done
    else
    # Parallel run. study panel join command broken so run only serial in that case.
	export -f create_chunk
	seq 0 $(( nodes * instances_per_node - 1 )) | parallel -j ${processes} create_chunk ${out_dir} ${chrom} ${instances_per_node} ${suffix}
    fi
fi
